{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For splitting data, hyperparam tuning, and evaluation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Transformers & pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Metrics (with custom F1 for pos_label='yes')\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, make_scorer\n",
    "\n",
    "# Classification models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Display settings for Pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "# pd.options.display.float_format = '{:.2f}'.format  # Optional numeric formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBased on the summary of the variables we can see the following important notes:\\n1) \\'unknown\\' values for several columns including \\n    job, material, education, defualt, housing, loan, duration\\n\\n2) Duration - there can be calls that were zero minutes meaning y was no. this input should only be included for \\n    benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\\n\\n3) pdays - 999 means client was not previously contacted. \\n\\n   Input variables:\\n   # bank client data:\\n   1 - age (numeric)\\n   2 - job : type of job (categorical: \"admin.\",\"blue-collar\",\"entrepreneur\",\"housemaid\",\"management\",\"retired\",\"self-employed\",\"services\",\"student\",\"technician\",\"unemployed\",\"unknown\")\\n   3 - marital : marital status (categorical: \"divorced\",\"married\",\"single\",\"unknown\"; note: \"divorced\" means divorced or widowed)\\n   4 - education (categorical: \"basic.4y\",\"basic.6y\",\"basic.9y\",\"high.school\",\"illiterate\",\"professional.course\",\"university.degree\",\"unknown\")\\n   5 - default: has credit in default? (categorical: \"no\",\"yes\",\"unknown\")\\n   6 - housing: has housing loan? (categorical: \"no\",\"yes\",\"unknown\")\\n   7 - loan: has personal loan? (categorical: \"no\",\"yes\",\"unknown\")\\n   # related with the last contact of the current campaign:\\n   8 - contact: contact communication type (categorical: \"cellular\",\"telephone\") \\n   9 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\\n  10 - day_of_week: last contact day of the week (categorical: \"mon\",\"tue\",\"wed\",\"thu\",\"fri\")\\n  11 - duration: last contact duration, in seconds (numeric). Important note:  this attribute highly affects the output target (e.g., if duration=0 then y=\"no\"). Yet, the duration is not known before a call is performed. \\n        Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\\n   # other attributes:\\n  12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\\n  13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\\n  14 - previous: number of contacts performed before this campaign and for this client (numeric)\\n  15 - poutcome: outcome of the previous marketing campaign (categorical: \"failure\",\"nonexistent\",\"success\")\\n   # social and economic context attributes\\n  16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\\n  17 - cons.price.idx: consumer price index - monthly indicator (numeric)     \\n  18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)     \\n  19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\\n  20 - nr.employed: number of employees - quarterly indicator (numeric)\\n\\n  Output variable (desired target):\\n  21 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Based on the summary of the variables we can see the following important notes:\n",
    "1) 'unknown' values for several columns including \n",
    "    job, material, education, defualt, housing, loan, duration\n",
    "\n",
    "2) Duration - there can be calls that were zero minutes meaning y was no. this input should only be included for \n",
    "    benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "3) pdays - 999 means client was not previously contacted. \n",
    "\n",
    "   Input variables:\n",
    "   # bank client data:\n",
    "   1 - age (numeric)\n",
    "   2 - job : type of job (categorical: \"admin.\",\"blue-collar\",\"entrepreneur\",\"housemaid\",\"management\",\"retired\",\"self-employed\",\"services\",\"student\",\"technician\",\"unemployed\",\"unknown\")\n",
    "   3 - marital : marital status (categorical: \"divorced\",\"married\",\"single\",\"unknown\"; note: \"divorced\" means divorced or widowed)\n",
    "   4 - education (categorical: \"basic.4y\",\"basic.6y\",\"basic.9y\",\"high.school\",\"illiterate\",\"professional.course\",\"university.degree\",\"unknown\")\n",
    "   5 - default: has credit in default? (categorical: \"no\",\"yes\",\"unknown\")\n",
    "   6 - housing: has housing loan? (categorical: \"no\",\"yes\",\"unknown\")\n",
    "   7 - loan: has personal loan? (categorical: \"no\",\"yes\",\"unknown\")\n",
    "   # related with the last contact of the current campaign:\n",
    "   8 - contact: contact communication type (categorical: \"cellular\",\"telephone\") \n",
    "   9 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "  10 - day_of_week: last contact day of the week (categorical: \"mon\",\"tue\",\"wed\",\"thu\",\"fri\")\n",
    "  11 - duration: last contact duration, in seconds (numeric). Important note:  this attribute highly affects the output target (e.g., if duration=0 then y=\"no\"). Yet, the duration is not known before a call is performed. \n",
    "        Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "   # other attributes:\n",
    "  12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "  13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "  14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "  15 - poutcome: outcome of the previous marketing campaign (categorical: \"failure\",\"nonexistent\",\"success\")\n",
    "   # social and economic context attributes\n",
    "  16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "  17 - cons.price.idx: consumer price index - monthly indicator (numeric)     \n",
    "  18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)     \n",
    "  19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "  20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "  Output variable (desired target):\n",
    "  21 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First top 15 rows:\n",
      "     age          job   marital            education  default housing loan    contact month day_of_week  duration  campaign  pdays  previous     poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y\n",
      "0    56    housemaid   married             basic.4y       no      no   no  telephone   may         mon       261         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "1    57     services   married          high.school  unknown      no   no  telephone   may         mon       149         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "2    37     services   married          high.school       no     yes   no  telephone   may         mon       226         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "3    40       admin.   married             basic.6y       no      no   no  telephone   may         mon       151         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "4    56     services   married          high.school       no      no  yes  telephone   may         mon       307         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "5    45     services   married             basic.9y  unknown      no   no  telephone   may         mon       198         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "6    59       admin.   married  professional.course       no      no   no  telephone   may         mon       139         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "7    41  blue-collar   married              unknown  unknown      no   no  telephone   may         mon       217         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "8    24   technician    single  professional.course       no     yes   no  telephone   may         mon       380         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "9    25     services    single          high.school       no     yes   no  telephone   may         mon        50         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "10   41  blue-collar   married              unknown  unknown      no   no  telephone   may         mon        55         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "11   25     services    single          high.school       no     yes   no  telephone   may         mon       222         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "12   29  blue-collar    single          high.school       no      no  yes  telephone   may         mon       137         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "13   57    housemaid  divorced             basic.4y       no     yes   no  telephone   may         mon       293         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "14   35  blue-collar   married             basic.6y       no     yes   no  telephone   may         mon       146         1    999         0  nonexistent           1.1          93.994          -36.4      4.857       5191.0  no\n",
      "\n",
      "Description of all columns:\n",
      "                 age     job  marital          education default housing   loan   contact  month day_of_week      duration      campaign         pdays      previous     poutcome  emp.var.rate  cons.price.idx  cons.conf.idx     euribor3m   nr.employed      y\n",
      "count   41188.00000   41188    41188              41188   41188   41188  41188     41188  41188       41188  41188.000000  41188.000000  41188.000000  41188.000000        41188  41188.000000    41188.000000   41188.000000  41188.000000  41188.000000  41188\n",
      "unique          NaN      12        4                  8       3       3      3         2     10           5           NaN           NaN           NaN           NaN            3           NaN             NaN            NaN           NaN           NaN      2\n",
      "top             NaN  admin.  married  university.degree      no     yes     no  cellular    may         thu           NaN           NaN           NaN           NaN  nonexistent           NaN             NaN            NaN           NaN           NaN     no\n",
      "freq            NaN   10422    24928              12168   32588   21576  33950     26144  13769        8623           NaN           NaN           NaN           NaN        35563           NaN             NaN            NaN           NaN           NaN  36548\n",
      "mean       40.02406     NaN      NaN                NaN     NaN     NaN    NaN       NaN    NaN         NaN    258.285010      2.567593    962.475454      0.172963          NaN      0.081886       93.575664     -40.502600      3.621291   5167.035911    NaN\n",
      "std        10.42125     NaN      NaN                NaN     NaN     NaN    NaN       NaN    NaN         NaN    259.279249      2.770014    186.910907      0.494901          NaN      1.570960        0.578840       4.628198      1.734447     72.251528    NaN\n",
      "min        17.00000     NaN      NaN                NaN     NaN     NaN    NaN       NaN    NaN         NaN      0.000000      1.000000      0.000000      0.000000          NaN     -3.400000       92.201000     -50.800000      0.634000   4963.600000    NaN\n",
      "25%        32.00000     NaN      NaN                NaN     NaN     NaN    NaN       NaN    NaN         NaN    102.000000      1.000000    999.000000      0.000000          NaN     -1.800000       93.075000     -42.700000      1.344000   5099.100000    NaN\n",
      "50%        38.00000     NaN      NaN                NaN     NaN     NaN    NaN       NaN    NaN         NaN    180.000000      2.000000    999.000000      0.000000          NaN      1.100000       93.749000     -41.800000      4.857000   5191.000000    NaN\n",
      "75%        47.00000     NaN      NaN                NaN     NaN     NaN    NaN       NaN    NaN         NaN    319.000000      3.000000    999.000000      0.000000          NaN      1.400000       93.994000     -36.400000      4.961000   5228.100000    NaN\n",
      "max        98.00000     NaN      NaN                NaN     NaN     NaN    NaN       NaN    NaN         NaN   4918.000000     56.000000    999.000000      7.000000          NaN      1.400000       94.767000     -26.900000      5.045000   5228.100000    NaN\n",
      "\n",
      "Non-null counts and data types for each column:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    '/Users/jimlopez/Desktop/AI Bootcamp/Practical Application Assignment 17.1- Comparing Classifiers/bank-additional/bank-additional-full.csv',\n",
    "    sep=';'\n",
    ")\n",
    "\n",
    "print(\"First top 15 rows:\\n\", df.head(15))\n",
    "print(\"\\nDescription of all columns:\\n\", df.describe(include='all'))\n",
    "# Observed: 'unknown' values for certain columns (education, default, etc.)\n",
    "\n",
    "print(\"\\nNon-null counts and data types for each column:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target Distribution:\n",
      "y\n",
      "no     36548\n",
      "yes     4640\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Null check per column:\n",
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp.var.rate      0\n",
      "cons.price.idx    0\n",
      "cons.conf.idx     0\n",
      "euribor3m         0\n",
      "nr.employed       0\n",
      "y                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Summaries about distribution of target\n",
    "print(f\"\\nTarget Distribution:\\n{df['y'].value_counts()}\")\n",
    "print(f\"\\nNull check per column:\\n{df.isnull().sum()}\")\n",
    "# We see no true NaN missing cells, but 'unknown' placeholders exist for some columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Including 'duration' for benchmark performance.\n",
      "\n",
      "=== Numeric Columns Description ===\n",
      "               age      duration      campaign         pdays      previous  emp.var.rate  cons.price.idx  cons.conf.idx     euribor3m   nr.employed\n",
      "count  41188.00000  41188.000000  41188.000000  41188.000000  41188.000000  41188.000000    41188.000000   41188.000000  41188.000000  41188.000000\n",
      "mean      40.02406    258.285010      2.567593    962.475454      0.172963      0.081886       93.575664     -40.502600      3.621291   5167.035911\n",
      "std       10.42125    259.279249      2.770014    186.910907      0.494901      1.570960        0.578840       4.628198      1.734447     72.251528\n",
      "min       17.00000      0.000000      1.000000      0.000000      0.000000     -3.400000       92.201000     -50.800000      0.634000   4963.600000\n",
      "25%       32.00000    102.000000      1.000000    999.000000      0.000000     -1.800000       93.075000     -42.700000      1.344000   5099.100000\n",
      "50%       38.00000    180.000000      2.000000    999.000000      0.000000      1.100000       93.749000     -41.800000      4.857000   5191.000000\n",
      "75%       47.00000    319.000000      3.000000    999.000000      0.000000      1.400000       93.994000     -36.400000      4.961000   5228.100000\n",
      "max       98.00000   4918.000000     56.000000    999.000000      7.000000      1.400000       94.767000     -26.900000      5.045000   5228.100000\n",
      "Numeric Columns: ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
      "\n",
      "=== Categorical Columns Description ===\n",
      "           job  marital          education default housing   loan   contact  month day_of_week     poutcome      y\n",
      "count    41188    41188              41188   41188   41188  41188     41188  41188       41188        41188  41188\n",
      "unique      12        4                  8       3       3      3         2     10           5            3      2\n",
      "top     admin.  married  university.degree      no     yes     no  cellular    may         thu  nonexistent     no\n",
      "freq     10422    24928              12168   32588   21576  33950     26144  13769        8623        35563  36548\n",
      "Categorical Columns: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome', 'y']\n"
     ]
    }
   ],
   "source": [
    "# Duration can leak info: if duration=0, often 'no'. \n",
    "# We'll keep it for now, but we can drop it if we want a real-time model.\n",
    "\n",
    "USE_DURATION = True\n",
    "if not USE_DURATION:\n",
    "    df.drop('duration', axis=1, inplace=True)\n",
    "    print(\"Excluding 'duration' for realistic pre-call predictive model.\")\n",
    "else:\n",
    "    print(\"Including 'duration' for benchmark performance.\")\n",
    "\n",
    "# Show numeric columns\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "print(\"\\n=== Numeric Columns Description ===\")\n",
    "print(numeric_df.describe(include='all'))\n",
    "\n",
    "numeric_cols = numeric_df.columns\n",
    "print(\"Numeric Columns:\", list(numeric_cols))\n",
    "\n",
    "# Show categorical columns\n",
    "categorical_df = df.select_dtypes(include=[np.object_])\n",
    "print(\"\\n=== Categorical Columns Description ===\")\n",
    "print(categorical_df.describe(include='all'))\n",
    "\n",
    "categorical_cols = categorical_df.columns\n",
    "print(\"Categorical Columns:\", list(categorical_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal is to predict if a client will subscirbe to a term deposit (column y: yes, no)\n",
    "# This would allow the bank to focust on high potential leads improving marketing efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Checking 'unknown' for each object column ===\n",
      "Column 'job' has 330 'unknown' values.\n",
      "Column 'marital' has 80 'unknown' values.\n",
      "Column 'education' has 1731 'unknown' values.\n",
      "Column 'default' has 8597 'unknown' values.\n",
      "Column 'housing' has 990 'unknown' values.\n",
      "Column 'loan' has 990 'unknown' values.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nColumn 'job' has 330 'unknown' values.\\nColumn 'marital' has 80 'unknown' values.\\nColumn 'education' has 1731 'unknown' values.\\nColumn 'default' has 8597 'unknown' values.\\nColumn 'housing' has 990 'unknown' values.\\nColumn 'loan' has 990 'unknown' values.\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to understand how many times 'unknown' appears in each object column.\n",
    "print(\"\\n=== Checking 'unknown' for each object column ===\")\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    unknown_count = (df[col] == 'unknown').sum()\n",
    "    if unknown_count > 0:\n",
    "        print(f\"Column '{col}' has {unknown_count} 'unknown' values.\")\n",
    "'''\n",
    "Column 'job' has 330 'unknown' values.\n",
    "Column 'marital' has 80 'unknown' values.\n",
    "Column 'education' has 1731 'unknown' values.\n",
    "Column 'default' has 8597 'unknown' values.\n",
    "Column 'housing' has 990 'unknown' values.\n",
    "Column 'loan' has 990 'unknown' values.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric columns used for preprocessing: ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
      "Categorical columns used for preprocessing: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('y', axis=1)  # all features except target\n",
    "y = df['y']               # target is 'yes'/'no'\n",
    "\n",
    "# Identify numeric vs. categorical columns for transformations\n",
    "numeric_cols_for_preproc = [\n",
    "    col for col in df.select_dtypes(include=[np.number]).columns \n",
    "    if col != 'y'\n",
    "]\n",
    "categorical_cols_for_preproc = [\n",
    "    col for col in df.select_dtypes(include=['object']).columns\n",
    "    if col != 'y'\n",
    "]\n",
    "\n",
    "print(\"\\nNumeric columns used for preprocessing:\", numeric_cols_for_preproc)\n",
    "print(\"Categorical columns used for preprocessing:\", categorical_cols_for_preproc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols_for_preproc),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols_for_preproc)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: (28831, 20), Test set: (12357, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "print(f\"\\nTrain set: {X_train.shape}, Test set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipelines & param grids in a dictionary to iterate.\n",
    "#(k-NN, Logistic Regression, Decision Tree, SVM)\n",
    "pipelines = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN\n",
    "knn_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "knn_param_grid = {\n",
    "    'knn__n_neighbors': [3, 5, 7, 11],\n",
    "    'knn__weights': ['uniform', 'distance']\n",
    "}\n",
    "pipelines['KNN'] = (knn_pipeline, knn_param_grid)\n",
    "\n",
    "# Logistic Regression\n",
    "logreg_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('logreg', LogisticRegression(solver='saga', max_iter=1000))\n",
    "])\n",
    "logreg_param_grid = {\n",
    "    'logreg__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'logreg__penalty': ['l1','l2']  # saga supports both\n",
    "}\n",
    "pipelines['LogisticRegression'] = (logreg_pipeline, logreg_param_grid)\n",
    "\n",
    "# Decision Tree\n",
    "tree_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('tree', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "tree_param_grid = {\n",
    "    'tree__criterion': ['gini','entropy'],\n",
    "    'tree__max_depth': [5, 10, 20, None],\n",
    "    'tree__min_samples_split': [2, 5, 10],\n",
    "    'tree__min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "pipelines['DecisionTree'] = (tree_pipeline, tree_param_grid)\n",
    "\n",
    "\n",
    "# SVM\n",
    "svm_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('svm', SVC(probability=True))\n",
    "])\n",
    "svm_param_grid = {\n",
    "    'svm__kernel': ['linear','rbf'],\n",
    "    'svm__C': [0.1, 1, 10, 100],\n",
    "    'svm__gamma': ['scale','auto']\n",
    "}\n",
    "pipelines['SVM'] = (svm_pipeline, svm_param_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_yes_scorer = make_scorer(f1_score, pos_label='yes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Now tuning hyperparameters for KNN ====\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best Params for KNN: {'knn__n_neighbors': 7, 'knn__weights': 'distance'}\n",
      "Test F1: 0.4938, Test Accuracy: 0.9044\n",
      "\n",
      "==== Now tuning hyperparameters for LogisticRegression ====\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Params for LogisticRegression: {'logreg__C': 10, 'logreg__penalty': 'l1'}\n",
      "Test F1: 0.5233, Test Accuracy: 0.9123\n",
      "\n",
      "==== Now tuning hyperparameters for DecisionTree ====\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Params for DecisionTree: {'tree__criterion': 'gini', 'tree__max_depth': 5, 'tree__min_samples_leaf': 1, 'tree__min_samples_split': 2}\n",
      "Test F1: 0.5707, Test Accuracy: 0.9150\n",
      "\n",
      "==== Now tuning hyperparameters for SVM ====\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimlopez/.pyenv/versions/3.13.0/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for SVM: {'svm__C': 10, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}\n",
      "Test F1: 0.5391, Test Accuracy: 0.9099\n",
      "\n",
      "=== MODEL COMPARISON TABLE ===\n",
      "                Model  Train Time (s)  Train Accuracy  Test Accuracy\n",
      "0                 KNN        5.602847        1.000000       0.904427\n",
      "1  LogisticRegression       29.540414        0.910999       0.912276\n",
      "2        DecisionTree        8.123339        0.916687       0.915028\n",
      "3                 SVM     2029.245218        0.954112       0.909930\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "model_results = {}\n",
    "comparison_table = []  # We'll store (model, train_time, train_accuracy, test_accuracy)\n",
    "\n",
    "for model_name, (model_pipeline, param_grid) in pipelines.items():\n",
    "    print(f\"\\n==== Now tuning hyperparameters for {model_name} ====\")\n",
    "    \n",
    "    # GridSearchCV with F1 (pos_label='yes')\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model_pipeline,\n",
    "        param_grid=param_grid,\n",
    "        scoring=f1_yes_scorer,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Track training (fit) time\n",
    "    start_time = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    train_time = end_time - start_time\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    # Predictions on test set\n",
    "    test_preds = best_model.predict(X_test)\n",
    "    # Predictions on training set (to see train accuracy)\n",
    "    train_preds = best_model.predict(X_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_acc = accuracy_score(y_test, test_preds)\n",
    "    train_acc = accuracy_score(y_train, train_preds)\n",
    "    test_f1 = f1_score(y_test, test_preds, pos_label='yes')\n",
    "    train_f1 = f1_score(y_train, train_preds, pos_label='yes')\n",
    "    \n",
    "    print(f\"Best Params for {model_name}:\", grid_search.best_params_)\n",
    "    print(f\"Test F1: {test_f1:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Store detailed results\n",
    "    model_results[model_name] = {\n",
    "        'best_model': best_model,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'test_preds': test_preds,\n",
    "        'train_preds': train_preds,\n",
    "        'test_accuracy': test_acc,\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_f1': test_f1,\n",
    "        'train_f1': train_f1,\n",
    "        'train_time': train_time\n",
    "    }\n",
    "    \n",
    "    # For a quick comparison table\n",
    "    comparison_table.append({\n",
    "        'Model': model_name,\n",
    "        'Train Time (s)': train_time,\n",
    "        'Train Accuracy': train_acc,\n",
    "        'Test Accuracy': test_acc\n",
    "    })\n",
    "\n",
    "# Present findings in a DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_table)\n",
    "print(\"\\n=== MODEL COMPARISON TABLE ===\")\n",
    "print(comparison_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "==== Now tuning hyperparameters for KNN ====\n",
    "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
    "Best Params for KNN: {'knn__n_neighbors': 7, 'knn__weights': 'distance'}\n",
    "Test F1: 0.4938, Test Accuracy: 0.9044\n",
    "\n",
    "==== Now tuning hyperparameters for LogisticRegression ====\n",
    "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
    "Best Params for LogisticRegression: {'logreg__C': 10, 'logreg__penalty': 'l1'}\n",
    "Test F1: 0.5233, Test Accuracy: 0.9123\n",
    "\n",
    "==== Now tuning hyperparameters for DecisionTree ====\n",
    "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
    "Best Params for DecisionTree: {'tree__criterion': 'gini', 'tree__max_depth': 5, 'tree__min_samples_leaf': 1, 'tree__min_samples_split': 2}\n",
    "Test F1: 0.5707, Test Accuracy: 0.9150\n",
    "\n",
    "==== Now tuning hyperparameters for SVM ====\n",
    "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
    "\n",
    "Best Params for SVM: {'svm__C': 10, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}\n",
    "Test F1: 0.5391, Test Accuracy: 0.9099\n",
    "\n",
    "=== MODEL COMPARISON TABLE ===\n",
    "                Model  Train Time (s)  Train Accuracy  Test Accuracy\n",
    "0                 KNN        5.602847        1.000000       0.904427\n",
    "1  LogisticRegression       29.540414        0.910999       0.912276\n",
    "2        DecisionTree        8.123339        0.916687       0.915028\n",
    "3                 SVM     2029.245218        0.954112       0.909930  \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Detailed Evaluation for KNN ===\n",
      "Best Params: {'knn__n_neighbors': 7, 'knn__weights': 'distance'}\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.93      0.97      0.95     10965\n",
      "         yes       0.61      0.41      0.49      1392\n",
      "\n",
      "    accuracy                           0.90     12357\n",
      "   macro avg       0.77      0.69      0.72     12357\n",
      "weighted avg       0.89      0.90      0.90     12357\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[10600   365]\n",
      " [  816   576]]\n",
      "\n",
      "=== Detailed Evaluation for LogisticRegression ===\n",
      "Best Params: {'logreg__C': 10, 'logreg__penalty': 'l1'}\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.93      0.97      0.95     10965\n",
      "         yes       0.67      0.43      0.52      1392\n",
      "\n",
      "    accuracy                           0.91     12357\n",
      "   macro avg       0.80      0.70      0.74     12357\n",
      "weighted avg       0.90      0.91      0.90     12357\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[10678   287]\n",
      " [  797   595]]\n",
      "\n",
      "=== Detailed Evaluation for DecisionTree ===\n",
      "Best Params: {'tree__criterion': 'gini', 'tree__max_depth': 5, 'tree__min_samples_leaf': 1, 'tree__min_samples_split': 2}\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.94      0.97      0.95     10965\n",
      "         yes       0.66      0.50      0.57      1392\n",
      "\n",
      "    accuracy                           0.92     12357\n",
      "   macro avg       0.80      0.73      0.76     12357\n",
      "weighted avg       0.91      0.92      0.91     12357\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[10609   356]\n",
      " [  694   698]]\n",
      "\n",
      "=== Detailed Evaluation for SVM ===\n",
      "Best Params: {'svm__C': 10, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.93      0.97      0.95     10965\n",
      "         yes       0.64      0.47      0.54      1392\n",
      "\n",
      "    accuracy                           0.91     12357\n",
      "   macro avg       0.79      0.72      0.74     12357\n",
      "weighted avg       0.90      0.91      0.90     12357\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[10593   372]\n",
      " [  741   651]]\n",
      "\n",
      "All done! We have baseline + tuned models (KNN, LogisticRegression, DecisionTree, SVM) and a comparison table. Feel free to expand.\n"
     ]
    }
   ],
   "source": [
    "# Printing final classification reports for each model\n",
    "for model_name, info in model_results.items():\n",
    "    print(f\"\\n=== Detailed Evaluation for {model_name} ===\")\n",
    "    print(\"Best Params:\", info['best_params'])\n",
    "    \n",
    "    # Classification report on Test set\n",
    "    print(\"Classification Report (Test):\")\n",
    "    print(classification_report(y_test, info['test_preds']))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(\"Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_test, info['test_preds']))\n",
    "\n",
    "\n",
    "print(\"\\nAll done! We have baseline + tuned models (KNN, LogisticRegression, DecisionTree, SVM) and a comparison table. Feel free to expand.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "=== Detailed Evaluation for KNN ===\n",
    "Best Params: {'knn__n_neighbors': 7, 'knn__weights': 'distance'}\n",
    "Classification Report (Test):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          no       0.93      0.97      0.95     10965\n",
    "         yes       0.61      0.41      0.49      1392\n",
    "\n",
    "    accuracy                           0.90     12357\n",
    "   macro avg       0.77      0.69      0.72     12357\n",
    "weighted avg       0.89      0.90      0.90     12357\n",
    "\n",
    "Confusion Matrix (Test):\n",
    "[[10600   365]\n",
    " [  816   576]]\n",
    "\n",
    "=== Detailed Evaluation for LogisticRegression ===\n",
    "Best Params: {'logreg__C': 10, 'logreg__penalty': 'l1'}\n",
    "Classification Report (Test):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          no       0.93      0.97      0.95     10965\n",
    "         yes       0.67      0.43      0.52      1392\n",
    "\n",
    "    accuracy                           0.91     12357\n",
    "   macro avg       0.80      0.70      0.74     12357\n",
    "weighted avg       0.90      0.91      0.90     12357\n",
    "\n",
    "Confusion Matrix (Test):\n",
    "[[10678   287]\n",
    " [  797   595]]\n",
    "\n",
    "=== Detailed Evaluation for DecisionTree ===\n",
    "Best Params: {'tree__criterion': 'gini', 'tree__max_depth': 5, 'tree__min_samples_leaf': 1, 'tree__min_samples_split': 2}\n",
    "Classification Report (Test):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          no       0.94      0.97      0.95     10965\n",
    "         yes       0.66      0.50      0.57      1392\n",
    "\n",
    "    accuracy                           0.92     12357\n",
    "   macro avg       0.80      0.73      0.76     12357\n",
    "weighted avg       0.91      0.92      0.91     12357\n",
    "\n",
    "Confusion Matrix (Test):\n",
    "[[10609   356]\n",
    " [  694   698]]\n",
    "\n",
    "=== Detailed Evaluation for SVM ===\n",
    "Best Params: {'svm__C': 10, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}\n",
    "Classification Report (Test):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          no       0.93      0.97      0.95     10965\n",
    "         yes       0.64      0.47      0.54      1392\n",
    "\n",
    "    accuracy                           0.91     12357\n",
    "   macro avg       0.79      0.72      0.74     12357\n",
    "weighted avg       0.90      0.91      0.90     12357\n",
    "\n",
    "Confusion Matrix (Test):\n",
    "[[10593   372]\n",
    " [  741   651]]\n",
    "\n",
    "All done! We have baseline + tuned models (KNN, LogisticRegression, DecisionTree, SVM) and a comparison table. Feel free to expand.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
